{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jewish-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-worth",
   "metadata": {},
   "source": [
    "### This is markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-farming",
   "metadata": {},
   "source": [
    "## a -> thêm 1 dòng trên"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-printing",
   "metadata": {},
   "source": [
    "esc/m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-virtue",
   "metadata": {},
   "source": [
    "## b -> thêm 1 dòng dưới"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-permission",
   "metadata": {},
   "source": [
    "# heading1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-canvas",
   "metadata": {},
   "source": [
    "## heading2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-fiber",
   "metadata": {},
   "source": [
    "**bôi đậm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-doctrine",
   "metadata": {},
   "source": [
    "*in nghiêng*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-excellence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rental-relevance",
   "metadata": {},
   "source": [
    "```\n",
    "My name is Nu\n",
    "From Viet Nam\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-extension",
   "metadata": {},
   "source": [
    "Chèn hình ảnh:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-operator",
   "metadata": {},
   "source": [
    "![]\n",
    "(https://file1.dangcongsan.vn/DATA/0/2018/10/68___gi%E1%BA%BFng_l%C3%A0ng_qu%E1%BA%A3ng_ph%C3%BA_c%E1%BA%A7u__%E1%BB%A9ng_h%C3%B2a___%E1%BA%A3nh_vi%E1%BA%BFt_m%E1%BA%A1nh-16_51_07_908.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-finger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "colonial-alexander",
   "metadata": {},
   "source": [
    "![](https://camo.githubusercontent.com/888e388801f947dec7c3d843942c277af25fe2b1aed1821542c4e711f210312a/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f632f63332f507974686f6e2d6c6f676f2d6e6f746578742e7376672f37363870782d507974686f6e2d6c6f676f2d6e6f746578742e7376672e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-invention",
   "metadata": {},
   "source": [
    "## Bắt Đầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "miniature-british",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acting-logan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-melissa",
   "metadata": {},
   "source": [
    "### 1. Operations - Toán Tử, Operator - Toán hạng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mexican-carroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affected-rings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "amended-brake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3333333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "noble-wrestling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100-70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ideal-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "entire-friendly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9%4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "subtle-orleans",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "round-arrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9 * 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hindu-transportation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9 ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "driving-frost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "pressed-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1j"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Số phức\n",
    "1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "intimate-affiliate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1j"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "respective-julian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1+0j)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1j) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-colleague",
   "metadata": {},
   "source": [
    "### 2. Data type and data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-welsh",
   "metadata": {},
   "source": [
    "Một chương trình máy tính = cấu trúc dữ liệu + thuật toán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-springfield",
   "metadata": {},
   "source": [
    "- numeric: int, float, complex\n",
    "- string\n",
    "- bolean: T or F\n",
    "- Nonetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adverse-kentucky",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "accomplished-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "wooden-indicator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "thrown-collector",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"phamnu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "union-august",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complex"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(1 + 2j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "amino-botswana",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type() takes 1 or 3 arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-ff6dcb82abed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: type() takes 1 or 3 arguments"
     ]
    }
   ],
   "source": [
    "type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unnecessary-century",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "weekly-tissue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True + True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "german-cotton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True + False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "later-slovak",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chuỗi 1Chuỗi 2'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"chuỗi 1\" + \"Chuỗi 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "congressional-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chuỗi 1Chuỗi 1Chuỗi 1Chuỗi 1Chuỗi 1Chuỗi 1Chuỗi 1Chuỗi 1Chuỗi 1Chuỗi 1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Chuỗi 1\" * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "objective-bottom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "metric-graphics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "metallic-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False and False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adopted-genealogy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False and True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "distinguished-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True or True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "advance-heart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "looking-honor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "collaborative-bullet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True and False or False or True and not False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "effective-suggestion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "green-finger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2<3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "classified-likelihood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3<=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "duplicate-register",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3 != 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-butler",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
